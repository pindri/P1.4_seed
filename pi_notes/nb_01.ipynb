{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course info**\n",
    "\n",
    "Numerical Approximation:\n",
    " - algotithms\n",
    " - analysis, error approximation\n",
    " - implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primciple is to replace difficult things with easier ones:\n",
    " - infinite dimensions $\\rightarrow$ finite dimensions\n",
    " - differential $\\rightarrow$ algebric\n",
    " - non linear $\\rightarrow$ linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subject of numerical analysis are **well posed problems**, often referred to as \"stable\" or \"insensitive\" problems. These are the only problems that we hope to approximate\n",
    " - there exists a unique solution\n",
    " - solution depends continuously from data, so \"small variations of input imply small variations of outputs\"\n",
    "\n",
    "**EX:**\n",
    "given a \"problem\", or a function $f$, and an evaluation point/input data x\n",
    "we want to compute $f(x) = y$. We have $\\hat{x}$ and $\\hat{y}$, the approximated input and outputs. What we are trying to compute is the **total error**, or\n",
    "\n",
    "$$\n",
    "\\hat{f}(\\hat{x})- f(x) = \\hat{f}(\\hat{x}) - f(\\hat{x}) + f(\\hat{x}) - f(x)\n",
    "$$\n",
    "\n",
    "the second part of the error is due to the propagation of the error on $x$. It is due to the stability of the problem itself: if the problem is not stable it will blow up. The first element is the error in the algorithm. They are both unavoidable, but if a problem is well posed  then you can ignore the second part, because you don't have control on that.\n",
    "\n",
    "Algorithm error (aka consistency error):\n",
    " - truncation error\n",
    " - rounding error\n",
    "\n",
    "**EX:** compute the first order derivative at a point $a$ as\n",
    "\n",
    "$$\n",
    "hat{f}(x) := \\frac{x(a+h) - x(a)}{h}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
